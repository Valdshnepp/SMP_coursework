
МИНИСТЕРСТВО НАУКИ И ВЫСШЕГО ОБРАЗОВАНИЯ РОССИЙСКОЙ ФЕДЕРАЦИИ
ФЕДЕРАЛЬНОЕ ГОСУДАРСТВЕННОЕ АВТОНОМНОЕ ОБРАЗОВАТЕЛЬНОЕ 
УЧРЕЖДЕНИЕ ВЫСШЕГО ОБРАЗОВАНИЯ
 «НОВОСИБИРСКИЙ НАЦИОНАЛЬНЫЙ ИССЛЕДОВАТЕЛЬСКИЙ ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ» (НОВОСИБИРСКИЙ ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ, НГУ)
Факультет ФИЗИЧЕСКИЙ
Кафедра ФТИ

	Направление подготовки 03.03.02 ФИЗИКА 
	Образовательная программа: БАКАЛАВРИАТ

ВЫПУСКНАЯ КВАЛИФИКАЦИОННАЯ РАБОТА
(проектно-исследовательский формат)
Корень Егор Александрович

Тема работы «Разработка системы журналирования данных инжекционного комплекса ВЭПП-5»


«К защите допущен»	
Заместитель заведующего кафедрой	Научный руководитель
Научный сотрудник с.5-12 ИЯФ СО РАН	Научный сотрудник с.5-12 ИЯФ СО РАН 

Чеблаков П.Б. /………….. 	
Еманов Ф.А./…………..
«……»………………2025г.	«……»………………2025г.

                        Дата защиты: «……»………………2025г.  

Новосибирск, 2025

 
Оглавление

1	Введение	3
2	Анализ существующих решений по журналированию данных	4
3	Обзор среды разработки	5
4	Реализация службы журналирования	7
4.1	Постановка задачи	7
4.2	Дополнительные инструменты разработки	9
4.3	Структура БД службы журналирования	9
4.4	Архитектура приложения журналирования	12
4.5	Установка на сервер и настройка systemd	14
4.6	Заключение по главе	15
5	Реализация графического приложения	16
5.1	Постановка задачи	16
5.2	Дополнительные инструменты разработки	16
5.3	Архитектура графического приложения	16
5.4	Обзор функционала и Взаимодействие компонентов приложения	17
5.5	Заключение по главе	19
6	Реализация приложения генерации отчетов	20
6.1	Постановка задачи	20
6.2	Дополнительные инструменты разработки	20
6.3	Структура БД хранения отчётов	20
6.4	Архитектура приложения генерации отчётов	21
6.5	Алгоритмы сбора метрик	23
6.6	Настройка Cron	25
6.7	Заключение по главе	25
7	Реализация сайта для отображения отчётов	27
7.1	Постановка задачи	27
7.2	Дополнительные инструменты разработки	27
7.3	Шаги разработки	27
7.4	Обзор функций сайта	28
7.5	Заключение по главе	30
8	заключение	31
9	Список литературы	32
10	Приложение	33

 
Введение
Инжекционный комплекс ВЭПП-5 (ИК) представляет собой источник высокоинтенсивных пучков электронов и позитронов, которые необходимы для функционирования коллайдеров ВЭПП-4М и ВЭПП-2000. ИК (рисунок 1) состоит из электронной пушки (источника электронов), двух линейных ускорителей (ЛУ), в которых происходит ускорение полученных частиц), конверсионной системы (”источника” антиматерии - позитронов), накопителя-охладителя (НО) и транспортного канала К-500 [1]. 
 
Рисунок 1. Схема инжекционного комплекса ВЭПП-5 (без каналов К-500)
Для объективного контроля работы ИК требуется система журналирования, которая представляет собой комплекс программ для записи, просмотра и визуализации данных, полученных как с оборудования ИК, так и с внутренних программных источников. Цель данной работы – разработка системы журналирования для ИК, обеспечивающей непрерывный сбор, визуализацию и анализ записанных данных. Для этого нужно решить следующие задачи:
	создание службы для непрерывного сбора и записи данных с аппаратного и программного обеспечения ИК;
	создание инструментов визуализации записанных данных;
	разработка алгоритмов анализа накопленных данных с расчётом ключевых метрик работы ИК.
Записанные данные можно использовать для обнаружения неправильной работы устройств, что служит поводом для проведения своевременных профилактических работ и предупреждения неисправностей. Более того, наличие временных данных (т.е. данных, характеризующих состояние ИК в различные моменты времени) является основой для дополнительных программ, таких как приложение для генерации отчетов, содержащих инфографику с важными параметрами и метриками о работе ИК, приложений анализа данных. Применение и рассмотрение результатов таких программ дают информацию о состоянии комплекса, могут служить источником идей для дальнейшей оптимизации работы ИК.
На ИК используется около 1000 устройств, каждое предоставляет несколько показателей, описывающих его состояние и доступных для считывания. Доступ к данным осуществляется посредством программной абстракции — канала, общее количество которых достигает примерно 6000. Суммарный поток данных со всех скалярных каналов достигает 10 Мб/с. Обработка информации такого объёма требует тщательного подбора методов записи и анализа. Неоптимизированные решения ведут к неоправданной нагрузке процессора, к необоснованному росту занимаемого дискового пространства и, как следствие, к значительным задержкам при доступе к данным. Оптимизация архитектуры обработки потока становится критическим фактором для обеспечения стабильной работы системы.
Система журналирования предназначена для работы на компьютерах под управлением ОС Linux и включает четыре взаимосвязанных приложения: службу журналирования, графический интерфейс для визуализации записанных данных, приложение генерации отчётов с ключевыми метриками и инфографикой о работе ИК, а также веб-сайт для представления отчётов. Все компоненты разработаны на Python, включая серверную часть сайта, реализованную на фреймворке Django. Клиентская сторона веб-интерфейса использует HTML и JavaScript для динамического отображения данных. Хранение информации организовано в системе управления базами данных (СУБД) PostgreSQL. Для взаимодействия с устройствами и программами используются средства фреймворка CXv4, используемого в качестве основного на ИК.
В рамках архитектуры системы созданы две специализированные базы данных: первая — для управления конфигурацией каналов журналирования и хранения записанных данных, вторая — для сохранения сформированных отчётов. Конфигурация каналов синхронизируется с основной конфигурационной базой данных ИК, содержащей актуальные сведения об устройствах. Для этого используется скрипт, который извлекает данные о каналах и параметры записи из общей конфигурационной БД и обновляет записи о каналах в специализированном хранилище. При этом устаревшие записи сохраняются, но отмечаются как вышедшие из работы. Такой подход не только обеспечивает актуальность данных при изменениях в инфраструктуре ИК, но и упрощает работу с записанными данными за счёт чёткого разделения конфигурационных данных и данных, предназначенных для настройки журналирования.
Компоненты системы журналирования представлены на рисунке 2. 
 
Рисунок 2. Схема компонент программного обеспечения

Анализ существующих решений по журналированию данных

В рамках задачи организации системы журналирования данных инжекционного комплекса ВЭПП-5 проведён сравнительный анализ трёх популярных решений систем журналирвоания: EPICS Archiver, Zabbix и Tango archiving system. Несмотря на их распространённость в индустрии, все системы демонстрируют фундаментальные ограничения, делающие их интеграцию в существующую систему управления ИК технически сложной или неоправданной из-за высоких требований к оборудованию.

Анализ существующих решений
	1. EPICS Archiver
	Недостатки:
	Решение рассчитано на системы управления с огромным числом каналов, поэтому избыточна для случая инжекционного комплекса.
	Требует крайне много ресурсов, в инструкции советуют использовать сервера с объемом оперативной памяти от 128 ГБ.
	2. Zabbix
	Недостатки:
	Zabbix представляет собой систему мониторинга сетевых устройств, и служит не только для записи данных. Поэтому Zabbix выполняет анализ данных для поиска проблем, оповещение о них и многие другие задачи. В ускорительной системе управления результаты оперативного анализа поступающих данных необходимы для корректной работы ускорителя. Поэтому обработка дынных возложена на программное обеспечение, интегрированное в систему управления ускорителя.
	Возможности редукции данных есть, но они не подходят для ускорительного применения. Например, записи по значимому изменению нет. Так же в Zabbix принято удалять устаревшие данные автоматически. Ограничений на установку срока хранения данных нет, но он конечен. Что представляется недопустимым для применения на ускорителях.
	Высокие накладные расходы: требует отдельной настройки триггеров, шаблонов и скриптов для обработки специфичных параметров ИК, что усложняет поддержку.
	3. Tango archiving system
	Недостатки:
	Узкая специализация: Tango archiving system требует полного соответствия серверной модели Tango для работы, что делает практически не возможным применение данного инструмента с другими фреймворками систем управления.

Указанные проблемы в существующих системах журналировния делают их применение на ИК не оправданным. Поэтому было принято решение о разработке системы журналирования специализированной для нужд комплекса.
Обзор среды разработки
Система журналирования представляет собой набор приложений, разработанных для интеграции в целевую среду — сервера и компьютеры под управлением ОС Linux. На ИК для управления устройствами реализовано ПО на языках C/C++ и Python. Соответственно они и являются возможными языками программирования (ЯП) для реализации приложений (другие решения не рассматриваются в связи с высокими затратами на их адаптацию). Python, как высокоуровневый язык программирования, был выбран для разработки приложения, что позволяет сократить сроки реализации в сравнении с низкоуровневыми языками, такими как C/C++. Использование python ведет к уменьшению шаблонного-кода, из-за лаконичности синтаксиса, что сокращает общий объем работы; python обладает богатой стандартной библиотекой, что избавляет от необходимости писать низкоуровневый код (В C++ аналогичные функции часто требуют подключения внешних библиотек (например, Boost), их настройки и ручного управления зависимостями); В python отсутствует этап компиляции, что ускоряет итеративную разработку. Также python обладает автоматическим управлением памятью, что избавляет разработчика от отладки потенциальных ошибок утечки памяти. Согласно исследованию [2], использование высокоуровневых языков с динамической типизацией (например, Perl и Smalltalk) сокращает время разработки в 3 раза по сравнению с C++. Поскольку Python обладает схожими чертами — динамической типизацией, управлением памятью и минималистичным кодом — логично предположить, что он обеспечивает сопоставимое ускорение процесса разработки. Эти аргументы подтверждают целесообразность выбора Python для реализации приложения.
Для взаимодействия с устройствами ИК используется фреймворк CXv4[3], представляющий собой систему управления, основанную на классической трехуровневой модели, схема которой представлена на рисунке 3. На прикладном уровне фреймворк предоставляет инструментарий для разработки службы журналирования, в том числе каналы — программные абстракции, обеспечивающие двусторонний обмен данными между приложениями (например, службой записи) и сервером CXv4. Каналы выступают виртуальными интерфейсами, инкапсулирующими протоколы взаимодействия с конкретными устройствами: они предоставляют доступ к их текущим параметрам и выступают посредником в передаче данных между сервером и прикладным уровнем. Для создания канала на уровне приложения формируется его экземпляр с уникальным именем, соответствующим целевому устройству или параметру в серверной базе данных; это имя служит идентификатором для установки соединения (возможно использование дополнительных аргументов для тонкой настройки поведения канала).
 
Рисунок 3. Схема CXv4
Модель устройства фреймворка схожа с моделью «Издатель — Подписчик» [4], где каналы выступают в роли издателей, а обработчики данных — подписчиков. Механизм работы включает следующие этапы:
	Подписка на канал: обработчик регистрируется для получения уведомлений о событиях (например, изменение значения или новое измерение).
	Генерация события: при изменении состояния канал автоматически инициирует событие.
	Обработка данных: зарегистрированные функции-обработчики вызываются по событию изменения значения канала. Это реализовано через событийную модель, где обновления данных генерируют сигналы, активирующие соответствующие обработчики для работы с актуальным состоянием канала
Такая архитектура обеспечивает непосредственную реакцию на изменения без активного опроса, снижая задержки и нагрузку на систему. Например, при обновлении значения датчика служба журналирования обрабатывает его, минуя этап ручного запроса.
В качестве СУБД выбран PostgreSQL, который уже используется для конфигурации ПО и хранения режимов на ИК. Это решение исключает необходимость внедрения дополнительных инструментов, что могло бы привести к: усложнению инфраструктуры накладным расходам на интеграцию (адаптация нового решения (настройка коннекторов, миграция данных, обучение команды - потребовали бы значительных временных и ресурсных затрат).
Преимуществами PostgreSQL для журналирования являются: активное сообщество разработчиков, наличие специализированных расширений и оптимизация. Активное сообщество способствует регулярным обновлениям, исправлениям уязвимостей и долгосрочной поддержке. Наличие расширений помогает достичь высокой производительности, так в проекте используется расширение TimescaleDB - специализированный инструмент для работы с временными рядами. PostgreSQL оптимизирован под высокие нагрузки, что достигается благодаря алгоритмам управления индексами.
TimescaleDB [5] интегрировано для эффективного хранения параметров устройств, которые по своей природе являются временными данными. Примерами оптимизаций являются: Автоматическое разделение данных по времени для быстрого доступа к актуальным записям; Снижение нагрузки на диск за счет сжатия старых данных (до 90% экономии пространства).
Для работы с базами данных используются система Django ORM [6] и модуль Psycopg2 [7]. Django ORM предоставляет простой интерфейс для работы с БД (в сравнении с SQL и применяется для операций не требующих высокой производительности (например, парсинг конфигурации). В местах, где оптимизация запросов к БД играет значительную роль используется Psycopg2. Это низкоуровневый адаптер PostgreSQL, оптимизированный для работы с БД. Psycopg2 выполняет SQL-запросы напрямую, что позволяет использовать пакетную вставку и избежать накладных расходов ORM.
Как итог: использование PostgreSQL + TimescaleDB обеспечивает баланс между совместимостью с существующей инфраструктурой, производительностью и масштабируемостью.
Реализация службы журналирования
Постановка задачи

Для обеспечения сбора информации и последующего анализа данных нужно разработать приложение-службу для непрерывной записи данных с ИК в базу данных PostgreSQL. Приложение журналирования должно быть способным вести запись круглосуточно, вести запись данных без потери информативности Учитывая необходимость бесперебойной работы, критически важными становятся устойчивость к сбоям (например, автоматическое восстановление после ошибок) и оптимизация. В рамках задачи необходимо:
	Спроектировать структуру БД, включающую две ключевые компоненты: конфигурации журналирования (список каналов, параметры записи), т.е. способы обработки и записи данных с устройств и результаты журналирования (данные с устройств).
	Реализовать приложение по журналированию, основанное на модульном принципе, обеспечив возможность расширения функционала. Поддерживаемые направления масштабирования: добавление новых протоколов взаимодействия с системами сбора данных (EPICS, CXv4), методов оптимизации (редукции) данных и форматов их сохранения.
На ИК используются каналы нескольких типов: скалярные, векторные и текстовые. Поток данных только со скалярных каналов достигает ~10Мб/c. Запись всего потока данных приведет к избыточному расходу дискового пространства. Более того сохранение всех данных приведет к снижению производительности БД (увеличение времени выполнения запросов из-за высокой нагрузки на хранилище).
Не все данные несут практическую ценность, так как многие АЦП периодически измеряют текущие характеристики ускорителя даже если в его состоянии нет изменений. Поэтому достаточно знать тренды изменений значений. Так, для мониторинга трендов ключевыми являются лишь значения, отражающие значимые изменения, а не малые отклонения.
Для выявления значимых изменений скалярных каналов используется следующий алгоритм: для канала задается порог отклонения. При поступлении нового значения, сравнивается с последним записанным. Если разница меньше порога, значение игнорируется. Иначе значение сохраняется как значимое. (формула 1)
█(|V_new-V_last |≥V_threshold#(1) )
Где Vnew – новое значение, Vlast – последнее записанное значение, Vthreshold – порог отклонения
Рассмотрены и протестированы другие алгоритмы редукции данных такие как алгоритм Веера (fan algorithm) [8]. Подобные алгоритмы требуют больше вычислений, за счет динамического конструирования ограничивающих условий, однако не дают большого выигрыша по сравнению с алгоритмом сравнения по порогу значения. 
Что касается фильтрации векторных каналов, то используется аналогичный подход – задается порог отклонения, который сравнивается с L2-нормой от разницы предыдущего записанного значения и нового значения. такой метод позволяет определять близость векторов и на основе этого решать – записывать значения или нет. (формула 2)
█(|(|V_new-V_last |)|_2≥V_threshhold#(2) )
Где Vnew – новый вектор, Vlast – последний записанный вектор, Vthreshold – порог отклонения
Для текстовых каналов редукция не используется в силу немногочисленности таких каналов и важности каждого нового изменения.
Даже с фильтрацией данных сохраняется проблема высокой нагрузки при записи в БД, так как каждая операция записи требует значительных ресурсов. Для оптимизации процесса предлагается накапливать данные в буфере и выполнять пакетную запись, что сокращает количество транзакций. Как показано в исследовании [9], такой подход снижает нагрузку на ЦП за счет уменьшения количества операций, но и увеличивает пропускную способность в ~30 раз.
Для работы с временными данными существует множество специализированных решений (QuestDB, InfluxDB, TimescaleDB). Данные решения направленны на оптимизацию запросов и хранение временных данных; дают существенное преимущество перед неспециализированными решением. Сравнение темпоральных БД приведено в приложении А. В данной работе используется TimescaleDB.

Дополнительные инструменты разработки

Для обеспечения круглосуточной и устойчивой работы служба журналирования настроена как служба в systemd — стандартную систему инициализации Linux. Systemd позволяет гибко настраивать условия запуска службы, ведет контроль над работой, systemd предоставляет информацию о работе приложения (journalctl), что помогает предотвращать и устранять критические проблемы. Systemd обеспечивает автоматический перезапуск службы в случае сбоя, позволяет настраивать зависимости (запуск службы журналирования только после запуска службы PostgreSQL).

Структура БД службы журналирования

На ИК используется конфигурационная база данных для хранения актуальной конфигурации устройств, однако она не подходит для журналирования из-за динамичности структуры: удаление или изменение данных об устройствах разрывает связь между архивными записями и их источниками, что приводит к потере смысла исторических данных (например, удаление устройства лишает его временные данные контекста). Для решения этой проблемы на основе информации конфигурационной БД создаются записи о каналах в БД журналирования. При удалении устройства из конфигурационной БД его каналы в БД журналирования помечаются как неактивные, что позволяет сохранить целостность исторических данных, обеспечивая связь между архивными записями и исходными каналами даже после изменения структуры комплекса.
При обновлении конфигурационной БД синхронизация данных с БД журналирования выполняется через специальный скрипт, который переносит изменения в структуре каналов из конфигурационной БД, сохраняя их исторические данные и настройки журналирования. Таким образом, обеспечивается согласованность между актуальной конфигурацией и архивными записями.
При проектировании БД журналирования было разработано 6 таблиц, описание и структура каждой приведены ниже.

Logchan (таблица 1) – таблица, содержащая основную информацию о канале и способы журналирования.

Таблица 1. Структура logchan
Название 	Тип данных 	Описание
Id	IntegerField	Id конфигурации
Chan_name 	CharField	Изначальное имя канала
Cur_chan_name	CharField	Актуальное имя канала
Is_log 	BooleanField	Флаг осуществления записи
Dtype	CharField	Тип данных канала
Dsize 	IntegerField	Размер данных канала (в байтах)
Log_batch_n	IntegerField	Размер буфера данных
Log_strat_id	ForeignField	Id применяемого метода редукции
Schange	FloatField	Значение порогового значения
Log_params	JsonField	Дополнительные параметры
Chan_id	ForeignField	Id канала
Dev_id	ForeignField	Id устройства
Protocol	CharField	Протокол чтения

Datalogh, Datalogh_vec и Datalogh_text (таблицы 2,3,4) представляют собой гипертаблицы — специализированный тип таблиц, реализуемый TimescaleDB для работы с временными данными. Гипертаблицы оптимизируют выполнение запросов и позволяют использовать алгоритмы сжатия. Каждая из указанных гипертаблиц хранит данные определённого типа: скалярные значения, векторные данные и текстовую информацию соответственно. 

Таблица 2. Структура Datalogh
Название 	Тип данных 	Описание
Data	FloatField	Данные 
In_timestamp	BigIntegerField	Время (с начала эпохи unix)
Logchan_id	ForeignKey	Ссылка на соответствующую конфигурацию

Таблица 3.Структура Datalogh_vec
Название 	Тип данных 	Описание
Data	ArrayField	Данные 
In_timestamp	BigIntegerField	Время (с начала эпохи unix)
Logchan_id	ForeignKey	Ссылка на соответствующую конфигурацию

Таблица 4. Структура Datalogh_text
Название 	Тип данных 	Описание
Data	TextField	Данные 
In_timestamp	BigIntegerField	Время (с начала эпохи unix)
Logchan_id	ForeignKey	Ссылка на соответствующую конфигурацию

HeartBeat (таблица 5) – гипертаблица статусов службы журналирования по времени (Начало работы, в процессе, завершение). 

Таблица 5. Структура HeartBeat
Название 	Тип данных 	Описание
Status	TextField	Статус службы
In_timestamp	BigIntegerField	Время (с начала эпохи unix)

Strats (таблица 6) – таблица, содержащая доступные методы редукции данных

Таблица 6. Структура Strats
Название 	Тип данных 	Описание
Id	IntegerField	Id метода редукции
Strat_name 	TextField	Название стратегии
Param_count	IntegerField	Количество принимаемых параметров

Представленные таблицы в виде ER-диаграммы изображены на рисунке 4.

 
Рисунок 4. ER-диаграмма базы данных службы журналирования
Реализация и управление схемой БД

Управление схемой базы данных в проекте реализовано на основе Django — фреймворка, который обеспечивает работу с БД через систему моделей. Модели — Python-классы, которые определяют структуру таблиц и связи между ними, абстрагируют низкоуровневые SQL-операции, позволяя описывать данные на Python, а Django автоматически транслирует это в SQL-запросы через ORM (Object-Relational Mapping). Преимущества моделей включают: сокращение рутинного кода за счет встроенных методов, гарантированную согласованность кода и схемы БД, автоматическую валидацию данных, удобный API для запросов (например, filter(), get()). Механизм миграций дополняет это: вместо ручного написания SQL-скриптов Django генерирует их на основе изменений в моделях, минимизируя риск ошибок и обеспечивая контроль версий схемы. Таким образом, связка «модели + миграции» делает управление БД предсказуемым, безопасным.

Анализ проблем и решения

Основная сложность при проектировании БД для службы журналирования заключалась в обработке большого потока временных данных. Для решения этой задачи было выбрано специализированное решение — TimescaleDB, расширение PostgreSQL, оптимизированное для работы с временными рядами. Его ключевая особенность — использование гипертаблиц, которые обеспечивают автоматическое разделение данных по времени, сжатие информации без потери производительности и ускорение временных запросов. Например, запросы к данным за определенный период выполняются в 2-3 раза быстрее по сравнению со стандартными таблицами PostgreSQL. Сравнение TimescaleDB с другими системами (InfluxDB, QuestDB) и метрики производительности приведены в приложении A.
Еще одной важной задачей стала оптимизация операций вставки данных, которые составляют основную нагрузку на БД. Для снижения числа запросов была реализована буферизация: данные накапливаются в памяти приложения и отправляются в БД массивом по 50-100 записей. Это позволило сократить количество сетевых вызовов и значительно снизить нагрузку на CPU (с ~60% до ~5% для Intel Xeon E5-2620 v3)

Интеграция с приложениями и оптимизация запросов

Взаимодействие с БД осуществляется через Django ORM для стандартных операций и библиотеку Psycopg2 для оптимизированных bulk-запросов (запросов массовой вставки). Например, вставка данных в гипертаблицы реализована через сырые SQL-запросы с использованием буферизации. Пример использования приведен в листинге 1. 

Листинг 1 – запрос вставки данных в БД
# Листинг 1 – Пакетная вставка данных в гипертаблицу
bulk_insert_data = ','.join(self.cursor.mogrify("(%s,%s,%s)", x).decode("utf-8") for x in
                                           ((channel_data.chan_id, channel_data.data[k], channel_data.timestamps[k]) for k in range(channel_data.element_count)))
self.cursor.execute("INSERT INTO datalog_h (log_chan_id, data, time) VALUES " + bulk_insert_data)
Здесь channel_data — структура буфера, содержащая идентификатор канала (chan_id), список значений (data) и временных меток (timestamps).

Таким образом, комбинация TimescaleDB для хранения временных данных и оптимизированных bulk-запросов позволила достичь высокой производительности системы даже при пиковых нагрузках.
Архитектура приложения журналирования 
Приложение реализовано на базе объектно-ориентированного проектирования с использованием паттернов:
	Фасад (CXv4LogSystem) — для упрощения взаимодействия с подсистемой журналирования.
	Стратегия (IStrategy) — для гибкой замены алгоритмов фильтрации данных.
	Интерфейсы (ILogger, IStrategy) — для обеспечения полиморфизма и соблюдения принципа открытости/закрытости (SOLID).
Основные модули приложения:
Таблица 7. основные модули приложения журналирования
Модуль	Роль	Паттерн
CXv4LogSystem	Центральный координатор: управляет каналами, фильтрами и логгерами	Фасад
DB_Parser	Чтение конфигурации из БД для настройки журналирования	—
IStrategy	Абстракция для алгоритмов фильтрации данных (например, L2-норма)	Стратегия (интерфейс)
ILogger	Абстракция для записи данных (в БД, файл, сбор статистики)	Интерфейс
Детализация компонентов
Класс DB_Parser отвечает за подключение к конфигурационной базе данных. Параметры соединения (хост, порт, учетные данные) передаются через конструктор класса. После успешного подключения метод parse_db() возвращает список параметров журналирования в виде кортежей: (имя канала, тип данных, метод фильтрации, параметры фильтрации). Этих данных достаточно для создания и настройки каналов записи.
Класс CXv4LogSystem реализует паттерн “Фасад” [4], упрощая взаимодействие с подсистемой журналирования. При создании объекта требуется объект класса ILogger и параметры каналов (результат работы DB_Parser). В процессе инициализации происходят следующие события:
	создаются объекты каналов с привязкой к методу chan_cb() (обратный вызов для обработки новых данных) 
	формируются фильтры (IStrategy) с указанными параметрами и ссылкой на логгер 
	для каждого канала устанавливается соответствия в виде записи в словаре канал – фильтр. При вызове chan_cb() данные канала преобразуются в унифицированный формат, после чего передаются в метод фильтра. Фильтр, в зависимости от стратегии (например, сравнение по l2-норме), решает, нужно ли передавать данные логгеру для записи.
Базовый класс IStategy, основанный на паттерне проектирования “Стратегия” [4], определяет абстрактный метод compare_data, который определяет интерфейс класса и обязателен для реализации классам наследникам. Примеры классов наследников AllValsStrat, L2DifStrat. Так при создании AllValStrat дополнительные параметры не используются, а реализация метода compare_data сводится к прямому обращению метода log_value() объекта класса ILogger. В случае L2DifStrat, цель которого фильтровать данные по условию превышения заданного порога при сравнении по l2-норме, уже требуются дополнительные параметры для определения порога, при этом обращение к логгеру происходит только при достаточном различии по l2-норме. 
Базовый класс ILogger определяет интерфейс взаимодействия класса, ответственного за запись данных. Основной метод – log_value, который определяет способ записи значения. Примерами классов наследников могут быть DBLogger и StatsLogger. Так DBLogger будет ответственным за запись данных в БД, когда цель класса StatsLogger в сборе статистики по каналам и записи результатов в файл. 
UML – диаграмма приложения представлена на рисунке 5. 
 
Рисунок 5. UML-диаграмма классов приложения
Последовательность взаимодействия компонентов
	Инициализация
	DB_Parser считывает конфигурацию журналирования из базы данных.
	Полученные параметры передаются в CX4LogSystem для дальнейшей обработки
	Настройка:
	CXv4LogSystem создает объекты каналов на основе конфигурации и в качестве метода обработки событий канала сопоставляет метод chan_cb ().
	К каждому каналу ставится в соответствии фильтр (IStrategy), отвечающий за редукцию данных. тип фильтра определяется из конфигурации.
	Фильтры связываются с объектом класса ILogger, который выполняет запись данных.
	Работа:
	 При поступлении новых данных с канала вызывается метод chan_cb(), который приводит данные канала к виду, соответствующего интерфейсу фильтров. 
	Данные передаются в фильтр (IStrategy.compare_data()), где анализируются на соответствии критериям редукции.
	Если данные удовлетворяют условиям, они записываются в базу данных через объект класса ILogger 
Установка на сервер и настройка systemd

Приложение загружается на целевой сервер через систему контроля версий Git, что обеспечивает прозрачность изменений и быструю интеграцию обновлений. Установка заключается в клонировании репозитория проекта и конфигурации рабочего окружения. Параметры среды задаются в файле LogServiceIni, который включает: пути к конфигурационной БД (хост, порт, учетные данные), директорию Django-проекта для работы с ORM.
Для управления службой создается unit-файл LogService.service (листинг 2).
Листинг 2. Создание unit файла 
	[Unit]  
Description=CXv4 logsystem service  
After=postgresql-16 # Запуск только после старта PostgreSQL  
Requires=postgresql-16 # Обязательная зависимость  
Conflicts=shutdown.target  # Запрет параллельной работы с процессом выключения  

[Service]  
User=ctlservices # Запуск от имени выделенного пользователя  
WorkingDirectory=…/logsystem
ExecStart=…/bin/python3 …/logsystem/CXv4logsystem.py  
Restart=on-failure  # Автоматический перезапуск при сбоях  
RestartSec=300  # Пауза перед перезапуском  

[Install]  
WantedBy=multi-user.target 
После создания unit-файла активируется автозапуск службы и обновляется конфигурация systemd. После чего служба готова к работе.
Преимуществами реализации:
	Надежность. Зависимость от PostgreSQL исключает потерю данных при перезапуске СУБД.
	Безопасность: Изоляция процессов через отдельного пользователя (log_service); Конфиденциальные данные (пароли БД) хранятся вне кода (в LogServiceIni).
Заключение по главе

В рамках раздела реализована служба журналирования данных инжекционного комплекса ВЭПП-5, обеспечивающая непрерывную запись, обработку и хранение параметров работы оборудования. Основные достижения в себя включают:
Оптимизированное хранение данных:
	Использование TimescaleDB (расширение PostgreSQL) позволило эффективно работать с временными рядами. Гипертаблицы обеспечили автоматическое разделение данных по времени и сжатие старых записей, что значительно снизило нагрузку на диск (согласно приложению А, уменьшение занимаемого дискового пространства при использовании подхода в ~ 60 раз).
	Схема БД включает разделение на конфигурационные (параметры каналов, методы редукции) и временные данные (скалярные, векторные, текстовые), что упростило масштабирование системы.
Обработка данных:
	Применение алгоритмов редукции (пороговое сравнение для скалярных каналов, L2-норма для векторных) и сжатия посредствам timescaleDB сократило объём сохраняемых данных на 99% без потери информативности. (объем накопленных данных скалярных каналов за месяц ~25ГБ, поток данных по скалярным каналам ~10Мб/c, что есть ~3240ГБ за месяц)
	Буферизация данных и пакетная вставка через Psycopg2 снизили нагрузку на CPU на c 60% до 5% по сравнению с построчной записью через Django ORM.
Интеграция с инфраструктурой:
	Использование PyCX4 обеспечило совместимость с существующими системами управления ИК.
	Интеграция в systemd гарантировали устойчивость службы: автоматический перезапуск при сбоях, зависимость от PostgreSQL.
Реализованная служба стала основой для последующих компонентов системы: графического приложения, генератора отчётов и веб-сайта.
Реализация графического приложения

Постановка задачи

Разработанная служба журналирования успешно записывает данные в БД, но их анализ остаётся сложным для большинства пользователей. Прямой доступ через SQL-запросы требует специализированных навыков, что ограничивает возможности сотрудников без технической подготовки. Даже простые задачи, такие как выбор временного диапазона или фильтрация каналов, превращаются в трудоёмкий процесс, сопряжённый с риском ошибок.

Для устранения этих ограничений разрабатывается графическое приложение, цель которого — предоставить интуитивный интерфейс для работы с данными без необходимости написания SQL-кода. Приложение позволит визуально выбирать устройства и каналы, задавать временные интервалы и строить графики с возможностью масштабирования, аннотаций и наложения данных за разные периоды. 

Дополнительные инструменты разработки
Графическое приложение разработано для интеграции на целевые компьютеры, работающие под управлением ОС Linux, где уже развернуто необходимое программное обеспечение (ПО). Для реализации используется Python. В основе приложения стоит фреймворк PyQt5 [10] с использованием модуля pyqtgraph для графического отображения временных зависимостей параметров устройств. Доступ к данным, хранящимся в БД, осуществляется при помощи psycopg2.

Архитектура графического приложения 

Графическое приложение разработано на базе фреймворка PyQt5, что обеспечивает кроссплатформенность и модульность структуры. На рисунке 6 представлена UML-диаграмма классов, отражающая ключевые компоненты системы и их взаимосвязи.

 
Рисунок 6. UML- диаграмма классов приложения

Детализация компонентов 

	Класс DevicePropertiesApp (наследник QMainWindow) — центральный класс приложения, управляющий главным окном. Инкапсулирует логику инициализации интерфейса, координацию виджетов и обработку событий верхнего уровня.

	Класс SysTreeWidget (наследник QTreeWidget) — реализует древовидное представление систем и подсистем устройств. Поддерживает множественное выделение элементов, эмитирует сигналы при изменении выбора для синхронизации с другими компонентами.

	Класс ChanListWidget (наследник QListView) — отображает список каналов выбранных устройств. Включает фильтрацию по имени, механизм множественного выбора и передачу данных о выбранных каналах в модель конфигурации.

	Класс OptionTreeWidget (наследник QTreeWidget) — контейнер для виджетов настройки. Группирует параметры отображения в раскрывающиеся секции для улучшения UX (user experience – пользовательский опыт взаимодействия с приложением).

	Класс TimeBoundarySelector (наследник QWidget) — виджет выбора временного интервала (начальная/конечная дата). Интегрирован в OptionTreeWidget, валидирует ввод и передаёт данные в формате Unix-времени.

	Класс ChanViewConfigList (наследник QWidget) — обеспечивает настройку визуализации каналов: выбор цвета линии, типа графика (линия, маркеры), толщины. Конфигурации хранятся в отдельной модели данных.

	Класс PlotWidget – основной виджет для построения графиков. Предоставляет возможности динамического масштабирования, панорамирование через жесты мыши. Есть возможность сохранения графиков и данных графиков в различных видах (png, csv)

Обзор функционала и Взаимодействие компонентов приложения
	Графический интерфейс приложения (Рисунки 7 и 8) спроектирован для интуитивного взаимодействия с данными устройств. Ниже представлена детализация ключевых функциональных блоков и их роль в рабочем процессе.
 
Рисунок 7. Вид графического приложения отображения данных (скалярные данные)
 
Рисунок 8. Вид графического приложения отображения данных (векторные данные)
Работа приложения следует паттерну «Наблюдатель» [4] с использованием сигнально-слотовой механики PyQt5:

	Выбор устройсв:
Выбираются устройства (SysTreeWidget, блок 1 рисунок 6), каналы устройств отображаются в ChanListWidget (блок 2 рисунок 6). Выбираются каналы из доступного списка (ChanListWidget).
	Настройка отображения:
В виджетах конфигурации (TimeBoundarySelector, ChanViewConfigList, блок 3 рисунок 6) настраивается временной промежуток отображения, способ отображения.
	Отображение:
После настройки идет отображение данных по средствам нажатия на кнопку. Данные загружаются из БД в соответствии с выбранными каналами и промежутком времени и визуализируются в PlotWidget (блок 4 рисунок 6).
Визуальная структура интерфейса
Описание и функционал основных классов представлены в таблице 8.
Таблица 8. структура интерфейса
Блок	Назначение	Функционал/Особенности
SysTreeWidget
(блок 1,
 рисунок 6)	Иерархическое представление устройств и их подсистем.	- Многоуровневое раскрытие узлов.
- Автоматическая синхронизация с ChanListWidget: выбор устройства обновляет список каналов в Блоке 2.
ChanListWidget
(блок 2,
 рисунок 6)	Отображение каналов выбранного устройства с поддержкой фильтрации.	- Разделение каналов на категории:
-Скалярные (одиночные значения).
-Векторные (массивы данных).
- Поиск по шаблону (регулярные выражения).
OptionTreeWidget
(блок 3,
 рисунок 6)	Настройка параметров отображения данных.	Состав:
-TimeBoundarySelector: выбор временного диапазона через календарь или ручной ввод.
-ChanViewConfigList: настройка цвета, типа линии, подписей. Поддержка импорта/экспорта профилей.
PlotWidget
(блок 3,
 рисунок 6)	Визуализация данных.	Режимы отображения:
- Скалярные данные: графики временных рядов.
- Векторные данные: осциллограммы.
Интерактивность:
- Локальное масштабирование (удержание правой кнопки мыши).
- Сравнение нескольких каналов.

Заключение по главе
Было разработано графическое приложение для анализа данных устройств, обеспечивающее гибкую визуализацию как скалярных, так и векторных параметров. Решение реализовано на базе фреймворка PyQt5, что позволило создать кроссплатформенный интерфейс с высокой степенью модульности и адаптивности.
Ключевые достижения:
	Эффективная архитектура:
	Чёткое разделение компонентов (SysTreeWidget, ChanListWidget, PlotWidget) по принципу единой ответственности упрощает поддержку и масштабирование кода.
	Использование сигнально-слотовой модели PyQt5 обеспечило слабую связность модулей интерфейса.
	Удобство взаимодействия:
	Интуитивная группировка функционала (древовидный выбор устройств, фильтрация каналов, настройки графиков) сокращает время освоения приложения.
	Поддержка режимов для скалярных (временные ряды) и векторных данных.
 

Реализация приложения генерации отчетов 

Постановка задачи

Для обеспечения объективного контроля за функционированием ИК было разработано приложение, автоматизирующее создание аналитических отчётов на основе данных, собираемых системой журналирования. Отчёты включают ключевые метрики производительности (времена работы в различных режимах), а также содержат визуализацию данных (например ток ускорителя ИК), структурированные по временным интервалам: смена, день, неделя, месяц, год. Решение предназначено для операторов, инженеров и научных сотрудников, участвующих в управлении ИК и анализе его работы, и должно предоставлять инструменты для быстрого выявления аномалий, оценки текущего состояния комплекса и принятия решений на основе агрегированной статистики.

Дополнительные инструменты разработки
Приложение для автоматизированной генерации отчётов предназначено для развёртывания на серверах под управлением ОС Linux и реализовано на языке Python. В качестве основы для работы с данными используется Django ORM, что упрощает работу с PostgreSQL. 
Обработка информации, включая агрегацию метрик и расчёт комплексной статистики, реализована с помощью библиотеки pandas, что гарантирует высокую производительность при работе с большими массивами данных.
Автоматизация процессов достигнута за счёт Git для контроля версий и Cron для планирования задач: генерация отчётов запускается по расписанию (смена/день/неделя), что минимизирует ручное управление и снижает риск ошибок.

Структура БД хранения отчётов

Для хранения данных отчётов разработана схема базы данных, включающая две таблицы: Category и Report. Их структура и назначение описаны ниже.

Category (таблица 9) хранит иерархическую информацию о временных промежутках (день, неделя, месяц, год), организованную в древовидную структуру БД. Такая модель позволяет включать меньшие периоды в состав более крупных — например, дни объединяются в недели, а недели — в месяцы, что упрощает как навигацию по отчётам, так и формирование агрегированных отчётов высшего уровня. Так, месячный отчёт автоматически собирается из данных недельных отчётов, сокращая время на расчёты и обеспечивая согласованность данных. Древовидная структура также оптимизирует навигацию и выборку информации, делая работу с историческими данными интуитивно понятной.

Таблица 9 - Структура Category
Название 	Тип Данных	Описание 
Title	CharField	Название периода 
Slug	SlugField	Уникальный идентификатор
Description	TextField	Описание 
Time_created	DateTimeField	Дата и время создания
Parent	TreeForeignKey	Ссылка на родительский период

Report (таблица 10) хранит сформированные аналитические отчёты, связанные с записями из таблицы Category. Каждый отчёт содержит данные за конкретный временной промежуток (смена, день, неделя и т.д.), включая метрики работы комплекса (время работы в режимах, токи, число частиц), графики и текстовые описания. 
 
Таблица 10. Структура Report
Название 	Тип данных 	Описание 
Category	TreeForeignKey	Ссылка на период из таблицы Category.
Title	CharField	Название отчёта
Slug	SlugField	Уникальный идентификатор отчёта
Short_description	Text_Field	Краткое описание отчёта
Full_description	Text_Field	Детальное описание
Time_created	DateTimeField	Дата и время создания отчёта
Report_type	CharField	Тип отчёта (смена/день/неделя и т.д.)
Modes_work_duration	JsonField	Время работы в режимах (e2v2, p2v2 и др.)
Modes_accum_times	JsonField	Время накопления пучков
Modes_sum_cur_particles	JsonField	суммарные токи и число частиц
Ic_plot	JsonField	График тока ИК
Vepp4_plot	JsonField	График тока ВЭПП4
Vepp2_plot	JsonField	График тока ВЭПП2

Представленные таблицы в виде ER-диаграммы изображены на рисунке 9. 

 
Рисунок 9. ER-диаграмма схемы БД хранения отчётов
Управление схемой БД происходит с использованием механизма миграций Django.

Архитектура приложения генерации отчётов

При проектировании приложения важно чётко определить задачи, которые оно решает. Основная цель — формирование отчётов различных типов: за смену, день, неделю и другие периоды. Все типы отчётов используют единую структуру в базе данных, что обеспечивает унифицированную работу с ними. Процесс создания отчёта можно сравнить с заполнением шаблона: общая логика остаётся неизменной, а различия касаются лишь специфики периода.

Для реализации этого подхода выбран паттерн “Шаблонный метод” [4]. Базовый класс IReportWorker определяет алгоритм генерации через метод generate_report(), который вызывает абстрактные методы (например, get_report_type(), get_work_times()) для получения уникальных параметров каждого типа отчёта. Классы-наследники (ShiftReportWorker, DayReportWorker и др.) реализуют эти методы, подстраивая логику под конкретный период. Например, ShiftReportWorker высчитывает необходимые метрики основываясь только на данных, записанных службой журналирования, а DayReportWorker уже агрегирует данные сменных отчётов.

Архитектура обеспечивает:
	Соблюдение SOLID: Принцип открытости/закрытости (расширение через новые классы, а не изменение существующих).
	Масштабируемость: Добавление нового типа отчёта требует только создания класса-наследника.
	Переиспользование кода: Общая логика генерации (сохранение в БД, валидация) вынесена в базовый класс.

Для создания отчёта требуется время запроса, для определения промежутка отчёта. Время и тип отчёта задается при запуске приложения в виде обязательных аргументов

Основные модули приложения и используемые паттерны [4]
	Фабрика (ReportWorkerFactory) – создает объекты классов-генераторов отчётов (например, ShiftReportWorker, DayReportWorker) на основе входных параметров (тип периода, время). Позволяет добавлять новые типы отчётов без изменения кода. 

	Шаблонный метод (IReportWorker) – Базовый класс определяет алгоритм генерации отчёта через метод generate_report(), который включает: загрузку данных из БД, расчет метрик (время работы, токи, частицы), формирование структуры отчёта, сохранение в БД.

Таблица 11. основные классы приложения генерации отчётов.
Модуль	Роль	Паттерн
ReportWorkerFactory	Создает экземпляры классов-генераторов на основе типа отчёта.	Фабрика
IReportWorker	Определяет шаблон генерации отчёта. Реализуется классами ShiftReportWorker, DayReportWorker и др	Шаблонный метод
UML-диаграмма приложения представлена на рисунке 10.

 
Рисунок 10. UML-диаграмма приложения генерации отчётов
Последовательность взаимодействие компонентов
	Запуск приложения происходит с использованием обязательных аргументов – время, за которое нужно сделать отчёт, тип отчета (смена, день, неделя и т.д.)
	На основе заданных параметров ReportWorkerFactory возвращает объект класса IReportWorker определенного типа, например, DayReportWorker.
	Вызывается метод созданного объекта generate_report(), который загружает необходимые данные из БД, рассчитывает метрики (агрегация времени работы, токов, частиц), составляет и сохраняет отчёт.

Алгоритмы сбора метрик

Метрики для отчётов формируются на основе данных службы журналирования, где ключевые параметры как ток ускорителя ИК, статусы оборудования (например выключатель пучка), режимы работы ИК сравниваются для определения состояния работы комплекса. Основная сложность — временная несогласованность данных: значения параметров фиксируются в разное время, что требует их синхронизации. Для решения применяется алгоритм аппроксимации (рисунок 11).

 
Рисунок 11. схема аппроксимации
Процесс включает четыре этапа. Сначала извлекаются данные за нужный период в формате списка пар «время — значение». Затем строится единая шкала времени, объединяющая все моменты записи параметров. На третьем этапе пропущенные значения интерполируются предыдущими известными (например, если параметр не менялся между записями, его значение считается постоянным). На четвертом этапе анализируются синхронизированные данные: для каждого интервала времени вычисляется режим работы, а их суммарная длительность формирует итоговые метрики.

Пример: расчет времени работы инжекционного комплекса (ИК) в режимах e2v2, p2v2, e2v4, p2v4. Участвуют параметры: ток (ic_current), статус магнита (Magnet), выключателя пучка (Beam), готовность потребителей (vepp2_ready, vepp4_ready) и целевой режим (mode). После аппроксимации для получения режима работы ИК данные проверяются по условиям таблицы 12 для каждого момента времени.

Таблица 12. Режимы работы Ик и условия режимов
Режим работы	ic_current	Magnet	Beam	vepp2_ready	vepp4_ready	mode
Пуск электронов на ВЭПП2000	≥ 1	1	1	1	N/A	e2v2
Пуск позитронов на ВЭПП2000	≥ 1	1	1	1	N/A	p2v2
Пуск электронов на ВЭПП4	≥ 1	1	1	N/A	1	e2v4
Пуск позитронов на ВЭПП4	≥ 1	1	1	N/A	1	p2v4
Тренировочные пуски	≥ 1	1	1	0	0	Любой/Нет
Простой	< 1	0	0	Любое	Любое	Любой/Нет


Время работы в каждом режиме суммируется и записывается в словарь work_times. Аналогично собираются другие метрики (время накопление пучков в ускорителе ИК, статистика передач пучка с ИК на потребителя), отличающиеся только условиями логики. Реализация алгоритма приведена в листинге 3.

Листинг 3. Пример вычисления времен работы ИК в различных режимах.

	for i in range(len(self.times)-1):
    if current[i]>1 and beam[i] and magnet[i]:
        if modes[i] in ('e2v2','p2v2') and vepp2_ready[i] == 1 or\
            modes[i] in ('e2v4','p2v4') and vepp3_status[i] == 1:
            work_times[modes[i]] += self.times[i+1] - self.times[i]
            self.work_state.append(modes[i])
        else:
            work_times['training'] += self.times[i+1] - self.times[i]
            self.work_state.append('training')
    else:
        work_times['sleep'] += self.times[i+1] - self.times[i]
        self.work_state.append('sleep')

Обоснование метода: интерполяция предыдущими значениями корректна, так как изменения параметров фиксируются службой журналирования. Это гарантирует, что между записями параметры остаются стабильными, что упрощает расчеты без потери точности.

Настройка Cron

Для автоматической генерации отчётов по расписанию используется Cron — стандартный планировщик задач в Linux. Настройка включает создание заданий для формирования отчётов:
	Отчеты за смены (каждые 12 часов):
	В 21:00 (после окончания дневной смены) и 9:00 (после ночной смены).
	Отчеты за сутки(9:00 следующего дня).
	Недельные отчёты(каждый понедельник в 9:00).
	Месячные отчёты (первое число месяца в 9:00).

листинг 4. Пример конфигурации Cron 
	0 21 * * * cd ../report-worker && ./venv/bin/python reportsapp.py -t shift
0 9 * * * cd ../report-worker && ./venv/bin/python reportsapp.py -t shift
3 9 * * * cd ../report-worker && ./venv/bin/python reportsapp.py -t day
6 9 * * 1 cd ../report-worker && ./venv/bin/python reportsapp.py -t week
9 9 1 * * cd ../report-worker && ./venv/bin/python reportsapp.py -t month
Т.к. отчёты за крупные периоды (день, неделя) требуют наличие меньших (смена требуется для создания отчёта за день), существует задержка между их созданием. создание отчёта откладывается на 1 час от начала смена (смены начинаются в 8:00/20:00), чтобы служба журналирования записала все данные с буфера, что происходит автоматически каждые 30 минут.

Заключение по главе

В рамках главы реализовано приложение для автоматизированной генерации аналитических отчётов о работе инжекционного комплекса. Ключевые результаты: 
	Создана схема БД для хранения отчётов о работе комплекса, включающих информацию о режимах работы, параметров пучков, статистику передач и накоплений. 
	Реализовано приложение по формированию отчётов на основе ранее записанных данных службой журналирования. В процессе разработки приложения были спроектированы и реализованы алгоритмы обработки данных для расчета метрик (Время работы комплекса в различных режимах, выпущенные токи, число частиц, статистика успешных передач пучка с инжекционного комплекса (ИК) на ускорители. Время накопления пучков, простои.)
	Автоматизирован запуск приложения по расписанию с использованием cron-заданий.

Применение паттернов «Фабрика» и «Шаблонный метод» обеспечило гибкость архитектуры, позволив легко добавлять новые типы отчётов.
 
Реализация сайта для отображения отчётов

Постановка задачи

Сформированные отчёты могут использоваться не только сотрудниками инжекционного комплекса, но и внешними потребителей — научными группами, руководителей проектов. Однако локальное графическое приложение, установленное на рабочих станциях ИК, ограничивает доступ к данным: для просмотра отчётов требуется физическое присутствие на комплексе или настройка VPN, что усложняет оперативное взаимодействие. Например, во время совещаний или презентаций необходимость демонстрации актуальной аналитики становится проблемой, если доступ к отчётам возможен только через внутренние системы.

Для устранения этих ограничений был разработан веб-сайт, предоставляющий удалённый доступ к отчётам через стандартный браузер. В отличие от графического приложения, веб-решение не требует установки дополнительного ПО, работает на любых устройствах и позволяет быстро делиться данными через ссылки. Архитектура сайта строится на технологиях:

	Серверная часть: Django (обработка запросов, интеграция с БД), Gunicorn (WSGI-сервер), Nginx (балансировка нагрузки, раздача статики).
	Клиентская часть: HTML/CSS для адаптивного дизайна, JavaScript с библиотекой Plotly для интерактивной визуализации графиков.

Таким образом, сайт становится универсальным инструментом для распространения аналитики.

Дополнительные инструменты разработки

Серверная часть сайта развёрнута в Docker-контейнерах, что позволяет быстро настраивать окружение на любых системах без зависимостей. В основе используется связка Django + Gunicorn + Nginx:

	Django обрабатывает бизнес-логику: загрузку данных из PostgreSQL, формирование HTML-страниц через шаблоны.
	Gunicorn выступает WSGI-сервером для запуска Django-приложения.
	Nginx обслуживает статические файлы (CSS, JS, изображения) и проксирует запросы к Gunicorn.

Для фронтенда применяется Bootstrap для адаптивного дизайна и Plotly для отрисовки графиков.
Шаги разработки

	Настройка Django-проекта

На первом этапе настраивается Django-проект: создаётся базовая структура, конфигурируются подключения к базе данных PostgreSQL (реализованной в главе 4 «Реализация приложения генерации отчётов»), а также модели Report и Category. Для проверки корректности работы моделей и взаимодействия с БД активируется административная панель Django. После успешного тестирования функционала через локальный сервер (python manage.py runserver) и подтверждения работоспособности начинаем разработку веб-страниц.

	Создание HTML-страниц с использованием шаблонов Django

Для создания HTML-страниц используется система шаблонов Django, обеспечивающая повторное использование кода и единый стиль. Базовый шаблон main.html определяет общую структуру: заголовок (<head>), верхнюю панель навигации и боковое меню. На его основе формируются две ключевые страницы:
	all_reports.html — отображает список всех отчётов в хронологическом порядке.
	detailed_report.html — выводит детализацию выбранного отчёта, включая графики и метрики.
Маршрутизация реализуется через Slug-поля моделей, которые генерируют уникальные URL на основе даты и типа отчёта. Например:
	localhost/reports/2025-03-12-1 — отчёт за дневную смену 12 марта 2025 года (суффикс 1 для дневной, 2 для ночной смены).
	localhost/reports/2025-03 — сводный отчёт за март 2025 года.

	Развертывание на сервере ИК.

На этапе развёртывания на сервере ИК настраивается связка Nginx + Gunicorn + Docker для обеспечения стабильной работы. Docker-контейнеризация упрощает перенос проекта: контейнеры инкапсулируют зависимости, а файл docker-compose.yml автоматизирует запуск Django и Nginx. Это позволяет развернуть сайт одной командой (docker-compose up -d), избежав ручной настройки окружения. Nginx принимает запросы пользователей, раздаёт статику (CSS, JS, изображения) и перенаправляет динамические запросы на Gunicorn. Gunicorn запускает Django-приложение, обрабатывая логику (работа с БД, формирование страниц) через несколько параллельных worker-процессов, что обеспечивает устойчивость под нагрузкой. Nginx защищает Gunicorn от прямого доступа извне, настраивает HTTPS и фильтрует атаки. 

Обзор функций сайта

Внешний вид главной страницы сайта представлен на рисунке 12. На главной странице представлен хронологический список отчётов с временными метками работы системы в различных режимах. Для навигации представлен интерактивный календарь, который позволяет фильтровать отчёты по датам формирования. Виды страниц, представляющие подробные отчёты, представлены на рисунках 13, 14,15. В дополнении к информации о временах работы в режимах они содержат информацию о токах ИК, статистику времен накоплений пучков ИК, общую сводку о работе ИК (количество пусков пучков, суммарные токи, количество выпущенных частиц за промежуток отчёта), коэффициенты передачи пучка с ИК потребителю.

 
Рисунок 12. Вид главной страница сайта отображения отчётов
 
Рисунок 13. Вид страницы подробного отчёта (1)
 
Рисунок 14.Вид страницы подробного отчёта (2)
 
Рисунок 15. Вид страницы подробного отчёта (3)

Заключение по главе 

В рамках главы реализован веб-сайт для отображения аналитических отчётов о работе ИК. Основной функционал включает:
	Наглядную навигацию по отчётам через календарь и фильтры.
	Краткое представление данных на главной странице (время работы в режимах, дата создания).
	Детальные страницы с графиками, таблицами и возможностью экспорта в PDF.
Для серверной части использован стек Django + PostgreSQL, что обеспечило быстрое взаимодействие с базой данных и гибкость в формировании страниц. Развёртывание в Docker-контейнерах упростило перенос приложения на рабочий сервер и настройку окружения. Связка Nginx + Gunicorn позволила оптимизировать обработку запросов и обслуживание статики.
Клиентская часть, реализованная на Bootstrap и Plotly, обеспечила адаптивный и интуитивно понятный интерфейс. Интеграция с модулем генерации отчётов выполнена через общую базу данных, что гарантирует актуальность отображаемой информации.
Итог: Сайт полностью решает поставленные задачи, предоставляя операторам и инженерам удобный инструмент для анализа работы комплекса
 
заключение

В ходе выполнения выпускной квалификационной работы была разработана система журналирования, анализа и визуализации данных инжекционного комплекса ВЭПП-5. Основной целью работы являлось создание инструментов, обеспечивающих непрерывный мониторинг, средства предоставления объективного контроля в виде отчётов. Поставленные задачи решены в полном объёме, что подтверждается следующими результатами:
	Служба журналирования на базе Python и TimescaleDB продемонстрировала высокую эффективность:
	Реализация алгоритмов редукции данных (пороговое сравнение для скалярных каналов, l2-норма для векторных) и применение алгоритмов сжатия значительно сократила объём хранимой информации без потери информативности.
	Использование буферизации и пакетной вставки через Psycopg2 снизило нагрузку на CPU с 60% до 5% при обработке 4500 каналов.
	Интеграция с PyCX4 и systemd обеспечила стабильную работу в промышленной среде, включая автоматический перезапуск при сбоях.
	Графическое приложение на основе PyQt5 предоставило интуитивный интерфейс для анализа данных:
	Поддержка скалярных и векторных параметров, динамическое масштабирование и фильтрация по времени упростили работу пользователей.
	Интеграция с TimescaleDB позволила сократить время отклика при запросах к данным до 0.002 секунды.
	Система генерации отчётов автоматизировала формирование аналитики:
	Применение паттернов «Фабрика» и «Шаблонный метод» обеспечило гибкость архитектуры, позволив легко добавлять новые типы отчётов.
	Использование Cron для планирования задач исключило ручное управление, минимизировав риск ошибок.
	Веб-сайт на базе Django стал универсальным инструментом для удалённого доступа к отчётам:
	Адаптивный дизайн и интерактивные графики улучшили взаимодействие с данными для сотрудников и внешних пользователей.
	Развёртывание в Docker-контейнерах упростило масштабирование и интеграцию с существующей инфраструктурой.
Практическая значимость работы заключается в повышении качества управления инжекционным комплексом за счёт:
	Своевременного выявления аномалий в работе оборудования.
	Упрощения анализа данных через визуализацию и автоматизацию отчётов.
	Снижения эксплуатационных затрат благодаря оптимизации хранения данных.
Разработанный программный комплекс успешно внедрён в эксплуатацию, подтвердив свою эффективность в условиях реальной нагрузки. 

 
Список литературы

1. Астрелина К.В., Блинов М.Ф., Всеволожская Т.А. и др. Production of intense positron beams at the VEPP-5 injection complex. – 2007. – URL: https://www.researchgate.net/publication/226792671_Production_of_intense_positron_beams_at_the_VEPP-5_injection_complex 

2. Макконнелл С. Сколько стоит программный проект / Пер. с англ. – М. : Русская редакция, 2007. – 297 с.

3. Болховитянов Д.Ю., Еманов Ф.А. VEPP-5 INJECTION COMPLEX CONTROL SYSTEM BASE SOFTWARE UPGRADE. – 2007. – URL: https://accelconf.web.cern.ch/rupac2018/papers/thpsc07.pdf 

4.  Гамма Э., Хелм Р., Джонсон Р., Влиссидес Дж. Приемы объектно-ориентированного проектирования. Паттерны проектирования = Design Patterns: Elements of Reusable Object-Oriented Software / Пер. с англ. – СПб. : Питер, 2015. – 368 с.

5. TimescaleDB Documentation: Hypertables and Compression [сайт]. – URL: https://docs.timescale.com/ – Яз. англ. – Текст: электронный.

6. Django Documentation: Models and ORM [сайт]. – URL:
https://docs.djangoproject.com/ – Яз. англ. – Текст: электронный.

7. Psycopg2 User Guide: Advanced Usage [сайт]. – URL:
https://www.psycopg.org/docs/usage.html – Яз. англ. – Текст: электронный.

8. Jalaleddine S. M. S., Hutchens C. G., Strattan R. D., Coberly W. A. ECG data compression techniques-a unified approach. – 1990. – URL: https://www.researchgate.net/publication/20969053_ECG_data_compression_techniques-a_unified_approach

9. Testing Postgres Ingest: INSERT vs. Batch INSERT vs. COPY [сайт]. – URL:
https://www.timescale.com/learn/testing-postgres-ingest-insert-vs-batch-insert-vs-copy?ref=timescale.com – Яз. англ. – Текст: электронный.

10. PyQt5 Official Documentation: Signal-Slot Architecture [сайт]. – URL:
https://doc.qt.io/qtforpython-5/contents.html – Яз. англ. – Текст: электронный.

11. Plotly Open Source Graphing Library [сайт]. – URL:
https://plotly.com/  – Яз. англ. – Текст: электронный.




 

Приложение 

Приложение А
Сравниваем следующие инструменты для работы с временными данными: стандартный PostgreSQL, PostgreSQL с расширением TimescaleDB, InfluxDB, QuestDB, Prometheus. Ограничимся данными инструментами как наиболее известными (занимают топ рейтингов по версиям [1,2,3]).  Для анализа будем опираться на следующие характеристики: размер хранимых данных, скорость записи данных, скорость обработки запросов, сложность внедрения, доступный инструментарий и уместность инструмента для решения нашей задачи.
Поскольку мы ограничены задачей журналирования, основными требованиями являются способность записи всех необходимых данных (инструмент должен обеспечивать достаточную скорость записи), оптимальный размер хранимых данных (должен соблюдаться баланс между объемом данных, скоростью записи и обработкой запросов) и возможность быстрой обработки запросов к базе данных. 
Кроме того, мы обратим внимание на избыточность решения и сложность внедрения. Избыточность инструмента может усложнить работу с ним и увеличить накладные расходы. Сложность внедрения также важна, так как возможность быстро и эффективно начать работать с инструментом напрямую влияет на итоговые результаты проделанной работы.
При оценке сложности внедрения в условиях ограниченных ресурсов ключевым фактором становится доступность инструмента для команды: например, PostgreSQL, благодаря распространенности SQL и обширной документации, позволяет быстро начать работу даже новичкам, а TimescaleDB, будучи его расширением, сохраняет привычный интерфейс, дополняя его оптимизированными функциями для временных рядов без необходимости изучения новых парадигм. В отличие от этого, InfluxDB, QuestDB и Prometheus требуют освоения специализированных языков запросов (InfluxQL, SQL с расширениями, PromQL) и глубокого понимания их внутренней архитектуры, что увеличивает время адаптации, а их интеграция в проект создает избыточное разнообразие технологий, усложняя поддержку и повышая порог вхождения для новых участников. Таким образом, выбор в пользу PostgreSQL/TimescaleDB минимизирует начальные затраты, снижает риски фрагментации кодовой базы и обеспечивает предсказуемость развития системы.
Однако стоит понимать основные преимущества данных решений, чтобы использовать их, если это действительно необходимо и где это будет стоить своих затрат на внедрение. InfluxDB, QuestDB, Prometheus позиционируются как специализированные решения для работы с темпоральными данными. Отличия заключаются в том, на какое место в процессе работы делается упор по оптимизации и в случае от потребностей задачи, такие конкретные места и будут определять применимость решения. QuestDB выделяется за счет эффективного механизма вставки новых записей, что в разы превосходит скорость вставки аналогичных инструментов. InfluxDB можно выделить за скорость обработки комплексных запросов. Prometheus, в отличие от предыдущих решений, ориентирован исключительно на мониторинг и алертинг в режиме реального времени, что делает его хорошим решением при потребности отслеживания состояния больших систем и сервисов [4,5].
Говоря о TimescaleDB трудно сказать, что по какому-то из вышеперечисленных аспектов будет превосходить другие инструменты, однако TimescaleDB реализует необходимые аспекты на уровне InfluxDB, QuestDB незначительно уступая в производительности.
Поэтому перед выбором Базы данных нужно знать параметры системы и требуемый функционал системы, над которой ведется работа. В нашем же случае возможностей TimescaleDB хватает, для обеспечения потребностей. Для нашей системы функционал InfluxDB, QuestDB, Prometheus оказывается избыточным. Поэтому выбор делается в пользу TimescaleDB
Изначально работа велась на чистом PostgreSQL без использования TimescaleDB. Однако, чтобы возможно было эффективно работать с большим потоком временных данных на чистом PostgreSQL был применен подход для хранения пакетной записи данных. Из начального вида записи {channel_id, value, timestamp}, где channel_id – внешний ключ на канал, который выдал значение, value – значение канала, timestamp – время получения данных переходим к пакетной записи, в которой поле value преобразуем в values_dict, теперь values_dict – словарь следующего типа {‘значения’: [список значений], ‘время записи’: [список временных меток, соответствующих значениям]}. Данный подход существенно уменьшает требуемое дисковое пространство, необходимое для хранения данных. При такой записи не возникает дополнительного разрастания занятого дискового пространства из-за записи метаинформации, которая пишется для каждой отдельной записи, что и делает начальный вид записи малоэффективным. Записей в целом становиться меньше, что делает запросы более быстрыми. Более того словарь хранится в бинарном представлении, что также снижает расходы на память. 
Однако такой подход лишает возможности писать удобные запросы из-за вида хранимых данных. При обработке приходиться объединять множество словарей, для проведения дальнейших операций над данными. Как итог: подход рабочий, но неудобный. Это и послужило мотивацией к исследованию специализированных решений. Как результат применяем TimescaleDB, который предоставляет возможность использовать удобный вид записи как {channel_id, value, timestamp}.
Проведем тестовые сравнения подходов при использовании обычной, пакетной записях в PostgreSQL, записи в PostgreSQL с использование TimescaleDB. Сравним занимаемое дисковое пространство данных для этих случаев и время исполнения запросов.
 
График 1. Зависимость скорости записи размера набора данных

На графике 1 отображены замеры скорости операций вставки в секунду между обычной таблицей PostgreSQL и гипертаблицей TimescaleDB. Скорость вставки двух решений значительно отличается, благодаря механизму секционирования гипертаблиц TimescaleDB.[6]
Далее сравним место необходимое для хранения записей. Результаты представлены в таблице 1.

	Default PostgreSQL	TimescaleDB
1kk	112mb	2mb
5kk	563mb	10mb
10kk	1127mb	19mb
рэйтинг	1 	0.016
Таблица 1. сравнение занимаемого пространства при использовании решений
До этого момента пакетная запись не шла в зачет. Понятно, что скорость одной записи в формате пакета будет такой же, как и у обычной записи, однако, если учесть, что в одном пакете может храниться информация о множество значений, то и общая скорость записи значительно больше. Стоит помнить, что пакеты приводят к проблемам с задержками записи (запись информации с датчика может долго дожидаться записи в базу данных, поскольку для записи необходимо полностью заполнить пакет) и трудности обработки данного пакетного формата. 
В плане компрессии данных, пакеты достаточно гибкие. Так размер пакета – параметр, определяющий насколько изменится размер записанных данных, скорость обработки запроса и задержкой до записи. 
Для сравнения по скорости выполнения запросов подберем размер пакета таким образом, чтобы размер записей примерно совпадал с размером записей в случае timescaleDB (10кк записей, размер пакета 100 ~ 21 Мб)
	Postgresql, с	Postgresql + пакеты,с	Timescale, с
Время получения	0.007	0.004	0.002
Время преобразования к рабочему виду* 	8.2	2.5	0.28
Рейтинг	0.03	0.112	1
Таблица 2. Сравнение скорости выполнения запросов при использовании решений ().
*рабочий вид, в данном случае приведение данных к виду, которые можно использовать для построения графиков (большая выборка, 100к записей).
 Имеет смысл использовать сравнительную характеристику как рейтинг, который можно посчитать как best_res/res_i
Таким образом приходим к выводу, что использование TimescaleDB уместно для нашего проекта. За счет его внедрения мы получаем возможность хранить данные в привычном формате, работать с ними, используя обычный SQL, достаточно эффективные операции вставки, компрессии и эффективное выполнение запросов.

Источники

	Time Series Databases Ranking [Сайт] // DragonflyDB. – URL: https://www.dragonflydb.io/databases/rankings/time-series (дата обращения: 29.05.2025).

	Top Time Series Databases [Сайт] // Timestored. – URL: https://www.timestored.com/data/top-timeseries-databases (дата обращения: 29.05.2025). 

	DB-Engines Ranking of Time Series DBMS [Сайт] // DB-Engines. – URL: https://db-engines.com/en/ranking/time+series+dbms (дата обращения: 29.05.2025). 

	QuestDB versus InfluxDB: Performance Comparison [Сайт] // QuestDB Blog. – URL: https://questdb.com/blog/2024/02/26/questdb-versus-influxdb/ (дата обращения: 29.05.2025). 

	What is Prometheus? [Сайт] // Prometheus Documentation. – URL: https://prometheus.io/docs/introduction/overview/ (дата обращения: 29.05.2025). – 

	Сравнение производительности InfluxDB и TimescaleDB в 2020 году [Сайт] // Хабр. – URL: https://habr.com/ru/companies/oleg-bunin/articles/464303/ (дата обращения: 29.05.2025).
